---
title: "Historical migration"
output:
  html_document:
    toc: true
    toc_float: true
knit: (function(inputFile, encoding) {
    rmarkdown::render(inputFile, encoding = encoding, output_dir = "../outputs/")
  })
---

```{r setup, include=TRUE, results= 'hide', message=FALSE}
library(igraph)
library(knitr)
# library(corrplot)
# library(corrgram)
library(rgdal)
library(tidyverse)
#library(spdplyr)
# library(geojsonio)
library(stplanr)
library(ggplot2)
#library(leaflet)
#library(SpatialPosition)
library(stargazer)
library(rprojroot)
library(cleangeo)
library(tmap)

# This is the project path
path <- find_rstudio_root_file()
```

## Migration flows

```{r}
path.data <- paste0(path, "/data/OD_MATRIX_1911/OD_MATRIX_FINAL_1911.txt" )

migration <- read_csv(path.data, col_names = T) %>% 
  rename(weight = POP_COUNT) %>% 
  rename(o = ORIG_SHAPEID,
         d = DEST_SHAPEID) %>% 
  mutate(
    # o = paste0(ORIG_X, "_", ORIG_Y ),    # unique origins coded as X_Y
    # d = paste0(DESR_X, "_", DEST_Y),   # unique destinations coded as X_Y
    od = paste0(o, "-", d)) %>%      # unique od pairs coded as X_Y-X_Y (o_o_d_d)
    group_by(od) %>%          
  summarise(weight = sum(weight)) %>%             # flows for each od pair 
  separate(od, c("o","d"), sep = "-") %>% # recreate unique o and d
  glimpse()                               # 12099 unique d and 
  
  
                                          # 20211 unique o, 11059 unique d
# length(unique(migration$o))
```

The below is with to exclude the intra-OA flows. 
**NOT TO RUN FOR NOW*

```{r eval=FALSE}

migration.intra <- migration %>% 
  filter(o == d)                   # 8779 / 2,809,977 intra flows

# migration <- migration %>% 
#   filter(o != d)
```

Given the size of the network I am using the `fast and greedy` community detection algorithm. 
The optimal number of communities is $12$.

The problem is that when I try to force $communities$ = $constituencies$ the communities after the $6th$ have only $1$ $OA$.
Therefore, I present the optimal solution here.


```{r communities}
net.migration <-graph_from_data_frame(migration, directed = TRUE, vertices = NULL)

# I need to look on the sensitivity of the below
# net.un <- as.undirected(net,
#                         mode=c("mutual"),
#                         edge.attr.comb = igraph_opt("edge.attr.comb"))

net.migration.un <- as.undirected(net.migration,
                        mode="collapse",
                        edge.attr.comb = igraph_opt("edge.attr.comb"))



# fast and greedy
fg.migration <- net.migration.un %>% 
  fastgreedy.community() 

V(net.migration.un)$group <- membership(fg.migration) # assign membership to vertices

sizes(fg.migration)

# fg$membership <- cut_at(fg, 543) 
# sizes(fg)
# for cut_at 543, the first 11 communities have > 1

names.migration <- vertex_attr(net.migration.un)[1]

df.migration <- cbind(as.data.frame(names.migration),
            fg.migration$membership) %>% 
  rename('community' = 'fg.migration$membership')

path.out <- paste0(path, "/outputs/fg_migration.csv")
write_csv(df.migration, path.out)
```

Other community detection attempts.

**Not to run**

```{r eval=FALSE}
# not hierarchical, I can't define cut_at
# l <- net.un %>% 
#   cluster_louvain() %>% 
#   cut_at(no = 543)



# Use spinglass to create a set number of communities
sg <- net %>% 
  cluster_spinglass(spins = 543) # 543 = the  number of constituencies allocated
                                 # to England for the 2023 Review

# Use hierarchical methods and cut_at to create a set number of communities 
walk <- net %>% 
  cluster_walktrap() %>% cut_at(no = 543) 

eb <- net %>% cluster_edge_betweenness() %>% cut_at(no = 10)


membership(net.l)
length(fg)
modularity(net.l)
print(net.l)
sizes(net.l)
is_hierarchical(net.l)

plot_dendrogram(net.l)

plot(lc, g)

```

## Mapping the communities

```{r mapping, include=TRUE, results= 'asis', message=FALSE}

path.poly <- paste0(path, "/data/OD_MATRIX_1911")

poly <- readOGR(path.poly, layer = 'RSD1911_conpar_par1851_SHAPEONLY_ENGLAND')

head(poly@data)

# Let's try to map our output. We need the local authorities shape file we have 
# already loaded

# Before we do any further analysis we make sure to convert the la object to WGS84 
# Longitude / Latitude Coordinate System.
wgs84 = '+proj=longlat +datum=WGS84'
poly <- spTransform(poly, CRS(wgs84) )

# This is the @data element of the la spatial object
head(poly@data)

# read data in case the community detection is not run
#df.migration <- read_csv(path.out)

# Let's merge it with the communities data frame
poly@data <- merge(poly@data, df.migration, by.x = "SHAPEID", by.y = "name", all.x = T)
sum(is.na(poly@data$community))
poly@data$community <- as.factor(poly@data$community)

# clean ploygons
poly <- clgeo_Clean(poly)

path.map.migration <- paste0(path, "/outputs/fg_migration.png")

fg.migration <- tm_shape(poly) + 
  tm_fill("community", 
          title= "Communities (fast and greedy)") + 
  tm_layout("Migration flows 1911")

tmap_save(fg.migration, path.map.migration)
```

## West Midlands

Community 5 is the West Midlands one.

```{r}
wm.migration <- induced_subgraph(net.migration.un, V(net.migration.un)$group==5)

#test <- induced_subgraph(wm.migration, which_multiple(wm.migration))

# The above creates multiple edges, no idea why.
# So, I simplify the graph
wm.migration <- igraph::simplify(wm.migration, 
                          remove.multiple = TRUE, 
                          remove.loops = TRUE,
                          edge.attr.comb = igraph_opt("edge.attr.comb")
                          )

# fast and greedy
fg.wm.migration <- wm.migration %>% 
  fastgreedy.community() 

V(wm.migration)$group <- membership(fg.wm.migration) # assign membership to vertices

sizes(fg.wm.migration)

# fg$membership <- cut_at(fg, 543) 
# sizes(fg)
# for cut_at 543, the first 11 communities have > 1

names.wm.migration <- vertex_attr(wm.migration)[1]

df.wm.migration <- cbind(as.data.frame(names.wm.migration),
            fg.wm.migration$membership) %>% 
  rename('community' = 'fg.wm.migration$membership')

path.out.wm.migration <- paste0(path, "/outputs/fg_wm.migration.csv")
write_csv(df.wm.migration, path.out.wm.migration)
```

## Map West Midlands communities

```{r}
path.poly <- paste0(path, "/data/OD_MATRIX_1911")

poly <- readOGR(path.poly, layer = 'RSD1911_conpar_par1851_SHAPEONLY_ENGLAND')

head(poly@data)

# Before we do any further analysis we make sure to convert the la object to WGS84 
# Longitude / Latitude Coordinate System.
wgs84 = '+proj=longlat +datum=WGS84'
poly <- spTransform(poly, CRS(wgs84) )


# read data in case the community detection is not run
#df <- read_csv(path.out.wm.migration)

# Let's merge it with the communities data frame
poly@data <- merge(poly@data, df.wm.migration, by.x = "SHAPEID", by.y = "name", all.x = T)
sum(is.na(poly@data$community))
poly@data$community <- as.factor(poly@data$community)

# clean polygons
poly <- clgeo_Clean(poly)

path.map.wm.migration <- paste0(path, "/outputs/fg_wm_migration.png")

fg.wm.migration <- tm_shape(poly) + 
  tm_fill("community", 
          title= "W. Midlands communities (fast and greedy)") + 
  tm_layout("Migration flows 1911")

tmap_save(fg.wm.migration, path.map.wm.migration)

wm.migration.for.geojson <- poly[!is.na(poly@data$community),]

path.out.wm.migration.geojson <- paste0(path, "/outputs/wm_migration_fg.geojson")
writeOGR(wm.migration.for.geojson, path.out.wm.migration.geojson, layer="meuse", driver="GeoJSON")
```
